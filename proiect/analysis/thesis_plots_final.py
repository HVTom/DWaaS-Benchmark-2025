# -*- coding: utf-8 -*-
"""THESIS-PLOTS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10WbFEV--EPziai-T8wmDDWUnmVgFYDJg
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('bq_combined.csv')

# filtrare operatii relevante
df = df[df['operation_type'].isin(['LOAD', 'QUERY', 'TRANSFORM'])]

# suma timpi pe operație și dimensiune
total_duration = df.groupby(['dataset_size', 'operation_type'])['duration_seconds'].sum().reset_index()

# ordonare dimensiuni
size_order = ['tiny', 'small', 'medium', 'large']
total_duration['dataset_size'] = pd.Categorical(total_duration['dataset_size'], categories=size_order, ordered=True)
total_duration = total_duration.sort_values(['operation_type', 'dataset_size'])

# aspect
plt.figure(figsize=(14, 8))
sns.set_style("whitegrid")
palette = sns.color_palette("Blues_d", n_colors=len(total_duration['operation_type'].unique()))

# grupare
ax = sns.barplot(
    x='dataset_size',
    y='duration_seconds',
    hue='operation_type',
    data=total_duration,
    palette=palette
)

# personalizare
plt.title('BigQuery: Timpii totali de procesare per operație și dimensiune', fontsize=16)
plt.xlabel('Dimensiunea dataset-ului', fontsize=12)
plt.ylabel('Timp total (secunde)', fontsize=12)
plt.legend(title='Tip operație', bbox_to_anchor=(1.05, 1), loc='upper left')

# adaugare valorile pe bare
for p in ax.patches:
    ax.annotate(
        f'{p.get_height():.2f}',
        (p.get_x() + p.get_width() / 2., p.get_height()),
        ha='center',
        va='center',
        xytext=(0, 10),
        textcoords='offset points'
    )

plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('bq_combined.csv')

# filtrare operații cu excludeere randuri SUMMARY)
df = df[df['operation_type'].isin(['LOAD', 'QUERY', 'TRANSFORM'])]

# media timpilor pe operatie si dimensiune
mean_duration = df.groupby(['dataset_size', 'operation_type'])['duration_seconds'].mean().reset_index()

# ordonare dimensiunile
size_order = ['tiny', 'small', 'medium', 'large']
mean_duration['dataset_size'] = pd.Categorical(mean_duration['dataset_size'], categories=size_order, ordered=True)
mean_duration = mean_duration.sort_values(['operation_type', 'dataset_size'])

# setari vizuale
plt.figure(figsize=(12, 8))
sns.set_style("whitegrid")
palette = sns.color_palette("viridis", n_colors=len(mean_duration['operation_type'].unique()))

# grafic grupat
ax = sns.barplot(
    x='dataset_size',
    y='duration_seconds',
    hue='operation_type',
    data=mean_duration,
    palette=palette
)

# etichete
plt.title('BigQuery: Media timpilor de procesare per tip de operație și dimensiune de dataset', fontsize=16)
plt.xlabel('Dimensiunea dataset-ului', fontsize=12)
plt.ylabel('Timp mediu (secunde)', fontsize=12)
plt.legend(title='Tip operație', bbox_to_anchor=(1.05, 1), loc='upper left')

# valorile pe bare
for p in ax.patches:
    ax.annotate(
        f'{p.get_height():.2f}',
        (p.get_x() + p.get_width() / 2., p.get_height()),
        ha='center',
        va='center',
        xytext=(0, 10),
        textcoords='offset points'
    )

plt.tight_layout()
plt.show()
##ADAUGA IN  LEGENDA INTERVALELE DE DIMENSIUNI PENTRU FISIERE PT FIECARE DATASET SIZE?

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

# incarcare date
df = pd.read_csv('bq_combined.csv')
summary_df = df[df['operation_type'].isin(['LOAD_COST', 'QUERY_COST', 'TRANSFORM_COST'])].copy()
size_order = ['tiny', 'small', 'medium', 'large']
summary_df['dataset_size'] = pd.Categorical(summary_df['dataset_size'], categories=size_order, ordered=True)
summary_df = summary_df.sort_values(['dataset_size', 'operation_type'])

# suprapunere grafice
fig, ax1 = plt.subplots(figsize=(12, 8))

# culori/operatie
colors = {'LOAD_COST': 'tab:blue', 'QUERY_COST': 'tab:green', 'TRANSFORM_COST': 'tab:orange'}
line_colors = {'LOAD_COST': 'tab:red', 'QUERY_COST': 'tab:purple', 'TRANSFORM_COST': 'tab:brown'}

# latime/pozitii bare
bar_width = 0.25
x = np.arange(len(size_order))

# barele pentru MB procesați (grupate)
for i, op in enumerate(['LOAD_COST', 'QUERY_COST', 'TRANSFORM_COST']):
    op_df = summary_df[summary_df['operation_type'] == op]
    positions = x + i * bar_width
    ax1.bar(positions, op_df['mb_processed'],
           width=bar_width,
           color=colors[op],
           alpha=0.7,
           label=f'MB procesați {op.replace("_COST", "")}')

# etichete axa primara MB
ax1.set_xlabel('Dimensiunea dataset-ului', fontsize=12)
ax1.set_ylabel('MB procesați', fontsize=12, color='black')
ax1.set_xticks(x + bar_width)
ax1.set_xticklabels(size_order)
ax1.tick_params(axis='y', labelcolor='black')

# axa secundară cost
ax2 = ax1.twinx()

# liniile cost
for i, op in enumerate(['LOAD_COST', 'QUERY_COST', 'TRANSFORM_COST']):
    op_df = summary_df[summary_df['operation_type'] == op]
    positions = x + i * bar_width
    ax2.plot(positions, op_df['cost_usd'],
            color=line_colors[op],
            marker='o',
            linewidth=2,
            markersize=8,
            label=f'Cost USD {op.replace("_COST", "")}')

# etichete axa secundara
ax2.set_ylabel('Cost USD', fontsize=12, color='black')
ax2.tick_params(axis='y', labelcolor='black')

# imbinare legendele
handles1, labels1 = ax1.get_legend_handles_labels()
handles2, labels2 = ax2.get_legend_handles_labels()
ax1.legend(handles1 + handles2, labels1 + labels2,
          loc='upper left', bbox_to_anchor=(1.05, 1))

plt.title('BigQuery: MB procesați și Cost USD per operație și dimensiune dataset', fontsize=14)
plt.tight_layout()
plt.show()

"""^^^^^^^^^^^^^^^^^^^^^^^^BIGQUERY^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

VVVVVVVVVVVVV**REDSHIFT**VVVVVVVVVVVVV
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

rs_df = pd.read_csv('rs_combined.csv')

df = rs_df[rs_df['operation_type'].isin(['LOAD', 'QUERY', 'TRANSFORM'])]

total_duration = df.groupby(['dataset_size', 'operation_type'])['duration_seconds'].sum().reset_index()

size_order = ['tiny', 'small', 'medium', 'large']
total_duration['dataset_size'] = pd.Categorical(total_duration['dataset_size'], categories=size_order, ordered=True)
total_duration = total_duration.sort_values(['operation_type', 'dataset_size'])

plt.figure(figsize=(14, 8))
sns.set_style("whitegrid")
palette = sns.color_palette("Reds_d", n_colors=len(total_duration['operation_type'].unique()))

ax = sns.barplot(
    x='dataset_size',
    y='duration_seconds',
    hue='operation_type',
    data=total_duration,
    palette=palette
)

plt.title('Redshift: Timpii totali de procesare per operație și dimensiune', fontsize=16)
plt.xlabel('Dimensiunea dataset-ului', fontsize=12)
plt.ylabel('Timp total (secunde)', fontsize=12)
plt.legend(title='Tip operație', bbox_to_anchor=(1.05, 1), loc='upper left')

for p in ax.patches:
    ax.annotate(
        f'{p.get_height():.2f}',
        (p.get_x() + p.get_width() / 2., p.get_height()),
        ha='center',
        va='center',
        xytext=(0, 10),
        textcoords='offset points'
    )

plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('rs_combined.csv')

df = df[df['operation_type'].isin(['LOAD', 'QUERY', 'TRANSFORM'])]

mean_duration = df.groupby(['dataset_size', 'operation_type'])['duration_seconds'].mean().reset_index()

size_order = ['tiny', 'small', 'medium', 'large']
mean_duration['dataset_size'] = pd.Categorical(mean_duration['dataset_size'], categories=size_order, ordered=True)
mean_duration = mean_duration.sort_values(['operation_type', 'dataset_size'])


dimensiuni_fisiere = {
    'tiny': '~80 MB',
    'small': '~500 MB',
    'medium': '~1 GB',
    'large': '~5 GB'
}

plt.figure(figsize=(14, 8))
sns.set_style("whitegrid")
palette = sns.color_palette("rocket", n_colors=len(mean_duration['operation_type'].unique()))

ax = sns.barplot(
    x='dataset_size',
    y='duration_seconds',
    hue='operation_type',
    data=mean_duration,
    palette=palette
)

plt.title('Redshift: Media timpilor de procesare per operație și dimensiune', fontsize=16)
plt.xlabel('Dimensiunea dataset-ului', fontsize=12)
plt.ylabel('Timp mediu (secunde)', fontsize=12)

xtick_labels = [f"{size}\n({dimensiuni_fisiere[size]})" for size in size_order]
ax.set_xticklabels(xtick_labels)

for p in ax.patches:
    ax.annotate(
        f'{p.get_height():.2f}',
        (p.get_x() + p.get_width() / 2., p.get_height()),
        ha='center',
        va='center',
        xytext=(0, 10),
        textcoords='offset points'
    )

handles, labels = ax.get_legend_handles_labels()
new_labels = []
for label in labels:
    if label == 'LOAD':
        new_labels.append('LOAD (încărcare date)')
    elif label == 'QUERY':
        new_labels.append('QUERY (interogări)')
    elif label == 'TRANSFORM':
        new_labels.append('TRANSFORM (transformări)')
    else:
        new_labels.append(label)

plt.legend(
    handles,
    new_labels,
    title='Tip operație',
    bbox_to_anchor=(1.05, 1),
    loc='upper left'
)

plt.tight_layout()
plt.show()

summary_rs = df_rs[df_rs['operation_type'].isin(['LOAD_COST', 'QUERY_COST', 'TRANSFORM_COST'])].copy()
summary_rs = summary_rs.dropna(subset=['mb_processed', 'cost_usd'])

summary_rs['dataset_size'] = pd.Categorical(summary_rs['dataset_size'], categories=size_order, ordered=True)
summary_rs = summary_rs.sort_values(['dataset_size', 'operation_type'])

fig, ax1 = plt.subplots(figsize=(12, 8))
colors = {'LOAD_COST': 'tab:blue', 'QUERY_COST': 'tab:green', 'TRANSFORM_COST': 'tab:orange'}
line_colors = {'LOAD_COST': 'tab:red', 'QUERY_COST': 'tab:purple', 'TRANSFORM_COST': 'tab:brown'}

bar_width = 0.25
x = np.arange(len(size_order))

for i, op in enumerate(['LOAD_COST', 'QUERY_COST', 'TRANSFORM_COST']):
    op_df = summary_rs[summary_rs['operation_type'] == op]
    positions = x + i * bar_width
    ax1.bar(
        positions,
        op_df['mb_processed'],
        width=bar_width,
        color=colors[op],
        alpha=0.7,
        label=f'MB {op.replace("_COST", "")}'
    )

ax1.set_xlabel('Dimensiunea dataset-ului', fontsize=12)
ax1.set_ylabel('MB procesați', fontsize=12)
ax1.set_xticks(x + bar_width)
ax1.set_xticklabels(size_order)

ax2 = ax1.twinx()
for i, op in enumerate(['LOAD_COST', 'QUERY_COST', 'TRANSFORM_COST']):
    op_df = summary_rs[summary_rs['operation_type'] == op]
    positions = x + i * bar_width
    ax2.plot(
        positions,
        op_df['cost_usd'],
        color=line_colors[op],
        marker='D',
        markersize=8,
        linewidth=2,
        label=f'Cost {op.replace("_COST", "")}'
    )

ax2.set_ylabel('Cost USD', fontsize=12)

handles1, labels1 = ax1.get_legend_handles_labels()
handles2, labels2 = ax2.get_legend_handles_labels()
ax1.legend(handles1 + handles2, labels1 + labels2, loc='upper left', bbox_to_anchor=(1.05, 1))

plt.title('Redshift: MB procesați și costuri per operație', fontsize=14)
plt.tight_layout()
plt.show()

"""^^^^^^^^^^^^^^ **REDSHIFT** ^^^^^^^^^^^^^

VVVVVVVVVVVVVVVV SYNAPSE VVVVVVVVVVVVVV
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

plt.clf()
plt.close('all')

dimensiuni_fisiere = {
    'tiny': '~80 MB',
    'small': '~500 MB',
    'medium': '~1 GB',
    'large': '~5 GB'
}

df = pd.read_csv('sy_combined.csv')

# conversie duration_seconds la numeric
df['duration_seconds'] = pd.to_numeric(df['duration_seconds'], errors='coerce')

df = df[df['operation_type'].isin(['LOAD', 'QUERY', 'TRANSFORM'])]

total_duration = df.groupby(['dataset_size', 'operation_type'])['duration_seconds'].sum().reset_index()

size_order = ['tiny', 'small', 'medium', 'large']
total_duration['dataset_size'] = pd.Categorical(total_duration['dataset_size'], categories=size_order, ordered=True)
total_duration = total_duration.sort_values(['dataset_size', 'operation_type'])

plt.figure(figsize=(14, 8))
plt.clf()
sns.set_style("whitegrid")
palette = sns.color_palette("Blues_d", n_colors=total_duration['operation_type'].nunique())

ax = sns.barplot(
    x='dataset_size',
    y='duration_seconds',
    hue='operation_type',
    data=total_duration,
    palette=palette
)

ax.set_ylim(0, total_duration['duration_seconds'].max() * 1.1)

plt.title('Synapse: Timpii totali de procesare per operație și dimensiune', fontsize=16)
plt.xlabel('Dimensiunea dataset-ului', fontsize=12)
plt.ylabel('Timp total (secunde)', fontsize=12)
plt.legend(title='Tip operație', bbox_to_anchor=(1.05, 1), loc='upper left')

for p in ax.patches:
    height = p.get_height()
    if height > 0:
        ax.annotate(
            f'{height:.2f}',
            (p.get_x() + p.get_width() / 2., height),
            ha='center',
            va='bottom',
            xytext=(0, 5),
            textcoords='offset points'
        )

plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('sy_combined.csv')

df = df[df['operation_type'].isin(['LOAD', 'QUERY', 'TRANSFORM'])]

df['duration_seconds'] = pd.to_numeric(df['duration_seconds'], errors='coerce')

mean_duration = df.groupby(['dataset_size', 'operation_type'])['duration_seconds'].mean().reset_index()

size_order = ['tiny', 'small', 'medium', 'large']
mean_duration['dataset_size'] = pd.Categorical(mean_duration['dataset_size'], categories=size_order, ordered=True)
mean_duration = mean_duration.sort_values(['operation_type', 'dataset_size'])

dimensiuni_fisiere = {
    'tiny': '~80 MB',
    'small': '~500 MB',
    'medium': '~1 GB',
    'large': '~5 GB'
}

plt.figure(figsize=(14, 8))
sns.set_style("whitegrid")
palette = sns.color_palette("mako", n_colors=len(mean_duration['operation_type'].unique()))

ax = sns.barplot(
    x='dataset_size',
    y='duration_seconds',
    hue='operation_type',
    data=mean_duration,
    palette=palette
)

plt.title('Synapse: Media timpilor de procesare per operație și dimensiune', fontsize=16)
plt.xlabel('Dimensiunea dataset-ului', fontsize=12)
plt.ylabel('Timp mediu (secunde)', fontsize=12)

xtick_labels = [f"{size}\n({dimensiuni_fisiere[size]})" for size in size_order]
ax.set_xticklabels(xtick_labels)

for p in ax.patches:
    ax.annotate(
        f'{p.get_height():.2f}',
        (p.get_x() + p.get_width() / 2., p.get_height()),
        ha='center',
        va='center',
        xytext=(0, 10),
        textcoords='offset points'
    )

handles, labels = ax.get_legend_handles_labels()
new_labels = []
for label in labels:
    if label == 'LOAD':
        new_labels.append('LOAD (încărcare date)')
    elif label == 'QUERY':
        new_labels.append('QUERY (interogări)')
    elif label == 'TRANSFORM':
        new_labels.append('TRANSFORM (transformări)')
    else:
        new_labels.append(label)

plt.legend(
    handles,
    new_labels,
    title='Tip operație',
    bbox_to_anchor=(1.05, 1),
    loc='upper left'
)

plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

df_sy = pd.read_csv('sy_combined.csv')

dimensiuni_fisiere = {
    'tiny': '~80 MB',
    'small': '~500 MB',
    'medium': '~1 GB',
    'large': '~5 GB'
}

summary_sy = df_sy[df_sy['operation_type'].isin(['LOAD_COST', 'QUERY_COST', 'TRANSFORM_COST'])].copy()
summary_sy = summary_sy.dropna(subset=['mb_processed', 'cost_usd'])

size_order = ['tiny', 'small', 'medium', 'large']
summary_sy['dataset_size'] = pd.Categorical(summary_sy['dataset_size'], categories=size_order, ordered=True)
summary_sy = summary_sy.sort_values(['dataset_size', 'operation_type'])

fig, ax1 = plt.subplots(figsize=(12, 8))
colors = {'LOAD_COST': 'tab:blue', 'QUERY_COST': 'tab:green', 'TRANSFORM_COST': 'tab:orange'}
line_colors = {'LOAD_COST': 'red', 'QUERY_COST': 'purple', 'TRANSFORM_COST': 'brown'}

bar_width = 0.25
x = np.arange(len(size_order))

for i, op in enumerate(['LOAD_COST', 'QUERY_COST', 'TRANSFORM_COST']):
    op_df = summary_sy[summary_sy['operation_type'] == op]
    positions = x + i * bar_width
    ax1.bar(
        positions,
        op_df['mb_processed'],
        width=bar_width,
        color=colors[op],
        alpha=0.7,
        label=f'MB {op.replace("_COST", "")}'
    )

ax1.set_xlabel('Dimensiunea dataset-ului', fontsize=12)
ax1.set_ylabel('MB procesați', fontsize=12)
ax1.set_xticks(x + bar_width)
ax1.set_xticklabels([f"{size}\n({dimensiuni_fisiere.get(size, '?')})" for size in size_order])

ax2 = ax1.twinx()
for i, op in enumerate(['LOAD_COST', 'QUERY_COST', 'TRANSFORM_COST']):
    op_df = summary_sy[summary_sy['operation_type'] == op]
    positions = x + i * bar_width
    ax2.plot(
        positions,
        op_df['cost_usd'],
        color=line_colors[op],
        marker='D',
        markersize=8,
        linewidth=2,
        label=f'Cost {op.replace("_COST", "")}'
    )

ax2.set_ylabel('Cost USD', fontsize=12)

handles1, labels1 = ax1.get_legend_handles_labels()
handles2, labels2 = ax2.get_legend_handles_labels()
ax1.legend(handles1 + handles2, labels1 + labels2, loc='upper left', bbox_to_anchor=(1.05, 1))

plt.title('Synapse: MB procesați și costuri per operație', fontsize=14)
plt.tight_layout()
plt.show()

"""DIAGRAME COMPARATIVE

"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# 3 fișiere CSV
sy = pd.read_csv('sy_combined.csv')
rs = pd.read_csv('rs_combined.csv')
bq = pd.read_csv('bq_combined.csv')

# coloana 'platform' INAINTE de filtrare
sy['platform'] = 'Synapse'
rs['platform'] = 'Redshift'
bq['platform'] = 'BigQuery'

# 3. conversie 'duration_seconds' la tip numeric
for df in [sy, rs, bq]:
    df['duration_seconds'] = pd.to_numeric(df['duration_seconds'], errors='coerce')

op_types = ['LOAD', 'QUERY', 'TRANSFORM']
sy = sy[sy['operation_type'].isin(op_types)]
rs = rs[rs['operation_type'].isin(op_types)]
bq = bq[bq['operation_type'].isin(op_types)]

# 5. toate datele într-un singur DataFrame
df_all = pd.concat([sy, rs, bq], ignore_index=True)

# 6. ordine dimensiuni si operatii
size_order = ['tiny', 'small', 'medium', 'large']
op_order = ['LOAD', 'QUERY', 'TRANSFORM']
df_all['dataset_size'] = pd.Categorical(df_all['dataset_size'], categories=size_order, ordered=True)
df_all['operation_type'] = pd.Categorical(df_all['operation_type'], categories=op_order, ordered=True)

# 7. observed=True - medie timpi
mean_duration = (
    df_all.groupby(['platform', 'dataset_size', 'operation_type'], observed=True)['duration_seconds']
    .mean()
    .reset_index()
)

# 8. BARE ORIZONTALE!!
sns.set_style("whitegrid")

g = sns.catplot(
    data=mean_duration,
    kind="bar",
    x="duration_seconds",    # durata pe axa X
    y="dataset_size",        # dimensiunea pe axa Y
    hue="platform",
    row="operation_type",
    palette="Set2",
    order=size_order,
    hue_order=['Synapse', 'Redshift', 'BigQuery'],
    row_order=op_order,
    height=4,
    aspect=1.5,
    orient='h'               # orientare orizontala
)

# LIMITEAZA SCALA pe axa X (0-250 secunde (synapse sare MULT))
for ax in g.axes.flat:
    ax.set_xlim(0, 100)      # xlim în loc de ylim

g.set_axis_labels("Durată medie (secunde)", "Dimensiunea dataset-ului")
g.set_titles("{row_name}")
g._legend.set_title("Platformă")
g.fig.suptitle("Comparatie timpi de procesare medii per operație și dimensiune dataset",
               fontsize=16, y=0.98)

plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

sy = pd.read_csv('sy_combined.csv')
rs = pd.read_csv('rs_combined.csv')
bq = pd.read_csv('bq_combined.csv')

# conversie la numeric pentru cost_usd
for df in [sy, rs, bq]:
    df['cost_usd'] = pd.to_numeric(df['cost_usd'], errors='coerce')

cost_ops = ['LOAD_COST', 'QUERY_COST', 'TRANSFORM_COST']
sy_cost = sy[sy['operation_type'].isin(cost_ops)].copy()
rs_cost = rs[rs['operation_type'].isin(cost_ops)].copy()
bq_cost = bq[bq['operation_type'].isin(cost_ops)].copy()

# adaugare coloana platform
sy_cost['platform'] = 'Synapse'
rs_cost['platform'] = 'Redshift'
bq_cost['platform'] = 'BigQuery'

# combinare fisiere
combined_cost = pd.concat([sy_cost, rs_cost, bq_cost], ignore_index=True)

# ordonare
size_order = ['tiny', 'small', 'medium', 'large']
op_order = ['LOAD_COST', 'QUERY_COST', 'TRANSFORM_COST']
combined_cost['dataset_size'] = pd.Categorical(combined_cost['dataset_size'], categories=size_order, ordered=True)
combined_cost['operation_type'] = pd.Categorical(combined_cost['operation_type'], categories=op_order, ordered=True)

# agregare cost mediu
mean_cost = combined_cost.groupby(['platform', 'dataset_size', 'operation_type'], observed=True)['cost_usd'].mean().reset_index()

# bare orizontale
sns.set_style("whitegrid")

g = sns.catplot(
    data=mean_cost,
    kind="bar",
    x="cost_usd",
    y="dataset_size",
    hue="platform",
    row="operation_type",
    palette="Set2",
    order=size_order,
    hue_order=['Synapse', 'Redshift', 'BigQuery'],
    row_order=op_order,
    height=4,
    aspect=1.5,
    orient='h'
)

g.set_axis_labels("Cost mediu (USD)", "Dimensiunea dataset-ului")
g.set_titles("{row_name}")
g._legend.set_title("Platformă")
g.fig.suptitle("Comparatie costuri medii per operație și dimensiune dataset", fontsize=16, y=0.98)

plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns

# stil diagrame
plt.style.use('default')
sns.set_palette("husl")

df_bq = pd.read_csv('bq_combined.csv')
df_bq = pd.DataFrame()

df_rs = pd.read_csv('rs_combined.csv')
df_rs = pd.DataFrame()

df_syn = pd.read_csv('sy_combined.csv')
df_syn = pd.DataFrame()


def print_csv_structure(filename, label):
    try:
        df = pd.read_csv(filename)
        print(f"\n=== STRUCTURA {label} ({filename}) ===")
        print(f"  Rows: {len(df):,}")
        print(f"  Columns: {len(df.columns)}")
        print(f"  Column names: {list(df.columns)}")
        print(f"  Data types:")
        for col, dtype in df.dtypes.items():
            print(f"    {col}: {dtype}")
        print(f"  Sample data (first 2 rows):")
        print(df.head(2).to_string(index=False))
        print("-" * 60)
        return df
    except Exception as e:
        print(f"  Nu s-a putut încărca {filename}: {e}")
        return pd.DataFrame()

# afisare structuri fisiere
df_bq = print_csv_structure('bq_combined.csv', 'BigQuery')
df_rs = print_csv_structure('rs_combined.csv', 'Redshift')
df_syn = print_csv_structure('sy_combined.csv', 'Synapse')


# un singur DataFrame
dfs = [df for df in [df_bq, df_rs, df_syn] if not df.empty]
if not dfs:
    print("Nu s-au găsit fișiere de date!")
    exit()

df = pd.concat(dfs, ignore_index=True)

# === COSTURI ===
cost_operations = df[df['operation_type'].isin(['LOAD_COST', 'QUERY_COST', 'TRANSFORM_COST'])]
cost_operations = cost_operations.dropna(subset=['cost_usd'])

if not cost_operations.empty:
    cost_df = cost_operations.groupby(['platform', 'operation_type'])['cost_usd'].mean().unstack(fill_value=0)
    cost_df = cost_df.rename(columns={
        'LOAD_COST': 'Avg_LOAD_Cost',
        'QUERY_COST': 'Avg_QUERY_Cost',
        'TRANSFORM_COST': 'Avg_TRANSFORM_Cost'
    })
else:
    cost_df = pd.DataFrame()

# === TIMPI ===
time_operations = df[df['operation_type'].isin(['LOAD', 'QUERY', 'TRANSFORM'])]
time_operations = time_operations.dropna(subset=['duration_seconds'])

if not time_operations.empty:
    time_df = time_operations.groupby(['platform', 'operation_type'])['duration_seconds'].mean().unstack(fill_value=0)
    time_df = time_df.rename(columns={
        'LOAD': 'Avg_LOAD_Time',
        'QUERY': 'Avg_QUERY_Time',
        'TRANSFORM': 'Avg_TRANSFORM_Time'
    })
else:
    time_df = pd.DataFrame()

# culori platforme
colors = {'BigQuery': '#4285F4', 'Redshift': '#FF9900', 'Synapse': '#00BCF2'}
operation_labels = ['LOAD', 'QUERY', 'TRANSFORM']
x = np.arange(len(operation_labels))
width = 0.25

available_platforms = [p for p in ['BigQuery', 'Redshift', 'Synapse'] if p in cost_df.index or p in time_df.index]
print(f"Platforme disponibile: {available_platforms}")

# === GRAFIC 1: COSTURI ===
if not cost_df.empty:
    fig_cost = plt.figure(figsize=(10, 6))
    ax_cost = fig_cost.add_subplot(111)

    for i, platform in enumerate(available_platforms):
        if platform in cost_df.index:
            costs = [cost_df.loc[platform, f'Avg_{op}_Cost'] for op in operation_labels]
            ax_cost.bar(x + i*width, costs, width, label=platform,
                        color=colors.get(platform, f'C{i}'), alpha=0.8)

    ax_cost.set_xlabel('Tip operație', fontsize=12)
    ax_cost.set_ylabel('Cost mediu (USD)', fontsize=12)
    ax_cost.set_title('Costuri medii per tip de operație', fontsize=14, fontweight='bold')
    ax_cost.set_xticks(x + width)
    ax_cost.set_xticklabels(operation_labels)
    ax_cost.legend()
    ax_cost.grid(True, alpha=0.3)

    # cost dasupra barelor
    for i, platform in enumerate(available_platforms):
        if platform in cost_df.index:
            costs = [cost_df.loc[platform, f'Avg_{op}_Cost'] for op in operation_labels]
            for j, cost in enumerate(costs):
                if cost > 0:
                    ax_cost.text(j + i*width, cost + max(costs)*0.02, f'${cost:.4f}',
                               ha='center', va='bottom', fontsize=9, fontweight='bold')

    plt.tight_layout()
    fig_cost.savefig('costuri_medii_per_operatie_separate.png', dpi=300, bbox_inches='tight')
    plt.show()

# === GRAFIC 2: TIMPI ===
if not time_df.empty:
    fig_time = plt.figure(figsize=(10, 6))
    ax_time = fig_time.add_subplot(111)

    for i, platform in enumerate(available_platforms):
        if platform in time_df.index:
            times = [time_df.loc[platform, f'Avg_{op}_Time'] for op in operation_labels]
            ax_time.bar(x + i*width, times, width, label=platform,
                        color=colors.get(platform, f'C{i}'), alpha=0.8)

    ax_time.set_xlabel('Tip operație', fontsize=12)
    ax_time.set_ylabel('Timp mediu (secunde)', fontsize=12)
    ax_time.set_title('Timpii medii per tip de operație', fontsize=14, fontweight='bold')
    ax_time.set_xticks(x + width)
    ax_time.set_xticklabels(operation_labels)
    ax_time.legend()
    ax_time.grid(True, alpha=0.3)

    # timpi deasupra barelor
    for i, platform in enumerate(available_platforms):
        if platform in time_df.index:
            times = [time_df.loc[platform, f'Avg_{op}_Time'] for op in operation_labels]
            for j, time_val in enumerate(times):
                if time_val > 0:
                    ax_time.text(j + i*width, time_val + max(times)*0.02, f'{time_val:.1f}s',
                               ha='center', va='bottom', fontsize=9, fontweight='bold')

    plt.tight_layout()
    fig_time.savefig('timpii_medii_per_operatie_separate.png', dpi=300, bbox_inches='tight')
    plt.show()

print("\nFigurile au fost salvate ca:")
print("- costuri_medii_per_operatie_separate.png")
print("- timpii_medii_per_operatie_separate.png")

# Afișăm statisticile
print("\n=== SUMAR COSTURI ===")
print(cost_df.round(6))
print("\n=== SUMAR PERFORMANȚĂ ===")
print(time_df.round(1))